{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bd9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1990fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "# word2vec packages\n",
    "import gensim.downloader as api\n",
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd85867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv(\"SMSSpamCollection.txt\", sep=\"\\t\", names=[\"label\",\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "efe8118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[\"message\"].loc[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a6c7bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ced18ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cgiuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ca440ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1375eb",
   "metadata": {},
   "source": [
    "### Clean the corpus: Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa3d9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus= []\n",
    "\n",
    "for i in range(0,len(texts)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', texts[\"message\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b88514f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri wkli comp win fa cup final tkt st may text fa receiv entri question std txt rate c appli',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though',\n",
       " 'freemsg hey darl week word back like fun still tb ok xxx std chg send rcv',\n",
       " 'even brother like speak treat like aid patent',\n",
       " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press copi friend callertun',\n",
       " 'winner valu network custom select receivea prize reward claim call claim code kl valid hour',\n",
       " 'mobil month u r entitl updat latest colour mobil camera free call mobil updat co free',\n",
       " 'gonna home soon want talk stuff anymor tonight k cri enough today',\n",
       " 'six chanc win cash pound txt csh send cost p day day tsandc appli repli hl info',\n",
       " 'urgent week free membership prize jackpot txt word claim c www dbuk net lccltd pobox ldnw rw',\n",
       " 'search right word thank breather promis wont take help grant fulfil promis wonder bless time',\n",
       " 'date sunday',\n",
       " 'xxxmobilemovieclub use credit click wap link next txt messag click http wap xxxmobilemovieclub com n qjkgighjjgcbl',\n",
       " 'oh k watch',\n",
       " 'eh u rememb spell name ye v naughti make v wet',\n",
       " 'fine way u feel way gota b',\n",
       " 'england v macedonia dont miss goal team news txt ur nation team eg england tri wale scotland txt poboxox w wq']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098fc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7ab6575",
   "metadata": {},
   "source": [
    "## Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3730c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=2500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74c3f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e7b37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encode dependent variable\n",
    "y=pd.get_dummies(texts['label'])\n",
    "y=y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337f3176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04d406",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "deb28c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 57)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96351c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d5bff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ced00d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred=spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2877434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97847533632287\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbebbc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       960\n",
      "           1       0.94      0.90      0.92       155\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.95      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64e47d",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2c9d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8cacc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load googles word2vec model\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "991c6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16e8894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, len(texts)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', texts['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e9ab51a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "83d1293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for sent in corpus:\n",
    "    sent_token=sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ded182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'bugis',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3c71aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5564"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20e7a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words,window=5,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b004e8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5564"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ae92da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3f8be8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work', 0.9984989762306213),\n",
       " ('even', 0.9984346628189087),\n",
       " ('wat', 0.9983864426612854),\n",
       " ('im', 0.9983823299407959),\n",
       " ('yet', 0.9983537197113037),\n",
       " ('buy', 0.9983491897583008),\n",
       " ('money', 0.9983407258987427),\n",
       " ('right', 0.9983381032943726),\n",
       " ('back', 0.9983358383178711),\n",
       " ('sorry', 0.9983318448066711)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('meeting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b715f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 0.9997450709342957),\n",
       " ('know', 0.9997392296791077),\n",
       " ('back', 0.99972003698349),\n",
       " ('come', 0.9997169971466064),\n",
       " ('time', 0.9997125267982483),\n",
       " ('said', 0.999695360660553),\n",
       " ('need', 0.9996944069862366),\n",
       " ('still', 0.999691367149353),\n",
       " ('going', 0.9996857047080994),\n",
       " ('go', 0.9996834993362427)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c8a269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['kid'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7bd854da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    #sent = [word for word in doc if word in model.wv.index_to_key]\n",
    "    #print(sent)\n",
    "    \n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)\n",
    "                #or [np.zeros(len(model.wv.index_to_key))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd33a099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['performed']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fad7bacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wait', 'still', 'clear', 'sure', 'sarcastic', 'want', 'live']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ab70cfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yeah', 'stand', 'close', 'tho', 'catch', 'something']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f040c544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ab4e8ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5564/5564 [00:01<00:00, 5493.62it/s]\n"
     ]
    }
   ],
   "source": [
    "#apply for the entire sentences\n",
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "#     print(\"Hi there\",i)\n",
    "    X.append(avg_word2vec(words[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f27b5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_new=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ec99edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.41740933e-01,  3.28980118e-01,  1.66340351e-01,  4.61039096e-02,\n",
       "        1.05386376e-01, -3.90552759e-01,  8.74172226e-02,  6.33390069e-01,\n",
       "       -2.15241134e-01, -1.19476676e-01, -1.88838065e-01, -4.60348636e-01,\n",
       "       -3.54975499e-02,  1.87713683e-01,  1.43454269e-01, -2.98695683e-01,\n",
       "        2.64999215e-02, -4.15612251e-01,  4.15876396e-02, -5.39947152e-01,\n",
       "        1.52854577e-01,  1.77938268e-01,  1.15594469e-01, -1.60323516e-01,\n",
       "       -1.25253186e-01,  2.37426162e-02, -2.14437366e-01, -2.00660810e-01,\n",
       "       -3.15333277e-01,  5.50206900e-02,  4.09245580e-01,  6.99922740e-02,\n",
       "        1.72828794e-01, -2.88164854e-01, -1.85448006e-01,  3.51725370e-01,\n",
       "       -9.55177378e-03, -2.65880316e-01, -1.95817396e-01, -5.15341520e-01,\n",
       "       -1.57512914e-04, -2.60490060e-01, -8.29297975e-02,  7.07969442e-02,\n",
       "        3.07807505e-01, -1.35636434e-01, -2.57891685e-01,  9.01011750e-03,\n",
       "        1.50920808e-01,  2.58330911e-01,  1.96551666e-01, -3.37062269e-01,\n",
       "       -7.17410967e-02, -2.46434081e-02, -1.89242855e-01,  2.23727345e-01,\n",
       "        1.88770160e-01, -6.13524280e-02, -3.73679787e-01,  1.24959424e-02,\n",
       "        1.06484331e-01,  1.79631904e-01, -1.76985621e-01,  2.46446878e-02,\n",
       "       -3.35239410e-01,  2.13822201e-01,  1.22295618e-01,  2.45465413e-01,\n",
       "       -3.13204557e-01,  3.81368488e-01, -2.20372126e-01,  1.41386449e-01,\n",
       "        3.23877484e-01, -6.57569394e-02,  3.46012384e-01,  2.61553735e-01,\n",
       "        1.12638222e-02, -1.26946867e-01, -2.75519341e-01,  1.54432431e-01,\n",
       "       -1.20417155e-01, -2.62377243e-02, -2.75405020e-01,  3.55842978e-01,\n",
       "       -6.18559308e-02, -1.15174381e-02, -1.14169516e-01,  4.16938186e-01,\n",
       "        4.80284363e-01,  1.15075909e-01,  4.40205961e-01,  1.93479732e-01,\n",
       "        8.51963386e-02,  1.33077502e-01,  4.53793734e-01,  3.33717257e-01,\n",
       "        1.51548147e-01, -3.98003250e-01,  1.50570884e-01, -8.30369592e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42d9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
